{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We actually worked on this algorithm in the main section but didn't get very good results, so this time we're going to make a simple modification to see if it works better. The modifications are mainly in the simplification of the algorithm and the simplification of the preprocessing."
      ],
      "metadata": {
        "id": "TTEHaeh5CIM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The platform used is anaconda's jupyter Notebook platform and the environment is self-configured.The detailed configuration information can be found in the final report."
      ],
      "metadata": {
        "id": "uz86jyOLEHgQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N2fcs4LCE3k"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_Bxj4DaZi0E"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUTDwYSm_QTx"
      },
      "outputs": [],
      "source": [
        "mbti_dataset_line = tf.data.TextLineDataset(\"DataBase_MBTI.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "83SkhV8H1wZT",
        "outputId": "c84b312e-adda-4195-a5df-13a376e2c14c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'type,posts,typescat,IE,NS,TF,JP', shape=(), dtype=string)\n",
            "tf.Tensor(b'INFJ,hello  ptypetoken  eostokendot  sorri  hear  your distress eostokendot   onli natur   relationship    perfect   time  everi moment  exist eostokendot    figur  hard time  time  growth  eostokendot  eostokendot  eostokendot     ,8,1,0,0,0', shape=(), dtype=string)\n",
            "tf.Tensor(b'INFJ,prozac wellbrutin  least thirti minut  move your leg   dont mean move them while sit  your same desk chair weed  moder mayb  edibl   healthier altern eostokendot  eostokendot  eostokendot     ,8,1,0,0,0', shape=(), dtype=string)\n",
            "tf.Tensor(b'INFJ,basic come  with three item youv determin that each type  whichev type  want   would more than like  given each type cognit function  whatnot when left  eostokendot  eostokendot  eostokendot     ,8,1,0,0,0', shape=(), dtype=string)\n",
            "tf.Tensor(b'INFJ, thing  moder eostokendot   sim  inde  video game   good   that eostokendot  note  good   that  somewhat subject  that    complet promot  death   given  eostokendot  eostokendot  eostokendot     ,8,1,0,0,0', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for ex in mbti_dataset_line.take(5):\n",
        "    print(ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY3QoTwzqjMD"
      },
      "outputs": [],
      "source": [
        "def label(line):\n",
        "  label =  tf.strings.substr([line],[-10],[1])\n",
        "  if label[0]==',':\n",
        "    label = tf.strings.substr([line],[-9],[1])\n",
        "  else:\n",
        "    label = tf.strings.substr([line],[-10],[2])\n",
        "  labelnum=tf.strings.to_number(label,tf.int64)\n",
        "  line= tf.strings.substr([line],[6],(tf.strings.length([line])-17))\n",
        "  return line[0], labelnum[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d9AlM9j2sTG"
      },
      "outputs": [],
      "source": [
        "\n",
        "mbti_dataset_line = mbti_dataset_line.skip(1).map(lambda line: label(line))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "8wg6GDg2ypU8",
        "outputId": "e6e5492a-2340-4728-d641-f8d7726735f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'ello  ptypetoken  eostokendot  sorri  hear  your distress eostokendot   onli natur   relationship    perfect   time  everi moment  exist eostokendot    figur  hard time  time  growth  eostokendot  eostokendot  eostokendot    '>, <tf.Tensor: shape=(), dtype=int64, numpy=8>)\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'rozac wellbrutin  least thirti minut  move your leg   dont mean move them while sit  your same desk chair weed  moder mayb  edibl   healthier altern eostokendot  eostokendot  eostokendot    '>, <tf.Tensor: shape=(), dtype=int64, numpy=8>)\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'asic come  with three item youv determin that each type  whichev type  want   would more than like  given each type cognit function  whatnot when left  eostokendot  eostokendot  eostokendot    '>, <tf.Tensor: shape=(), dtype=int64, numpy=8>)\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'thing  moder eostokendot   sim  inde  video game   good   that eostokendot  note  good   that  somewhat subject  that    complet promot  death   given  eostokendot  eostokendot  eostokendot    '>, <tf.Tensor: shape=(), dtype=int64, numpy=8>)\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'ear  ptypetoken   what were your favorit video game grow   what  your  current favorit video game eostokenquest  cool   '>, <tf.Tensor: shape=(), dtype=int64, numpy=8>)\n"
          ]
        }
      ],
      "source": [
        "for ex in mbti_dataset_line.take(5):\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGKRMFWzqd87"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 100000\n",
        "BATCH_SIZE = 64\n",
        "TAKE_SIZE = 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YADuNtEqdu-"
      },
      "outputs": [],
      "source": [
        "mbti_dataset_line = mbti_dataset_line.shuffle(\n",
        "    BUFFER_SIZE, reshuffle_each_iteration=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "m0yWIbr2G_fs",
        "outputId": "daa49757-748e-4172-883f-a9fd5c91a9ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "83501"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = tfds.features.text.Tokenizer()\n",
        "\n",
        "vocabulary_set = set()\n",
        "for text_tensor, _ in mbti_dataset_line:\n",
        "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
        "  vocabulary_set.update(some_tokens)\n",
        "\n",
        "vocab_size = len(vocabulary_set)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIPpa3ueL4T8"
      },
      "outputs": [],
      "source": [
        "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "KXrIdaUFMCun",
        "outputId": "bb005dc5-b868-4d06-fc2b-0153ad286af0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b' love  give  gift  freedom  someon els eostokendot   allow    love   their authent self without tri  chang  correct them   most unselfish    represent eostokendot  eostokendot  eostokendot    '\n"
          ]
        }
      ],
      "source": [
        "example_text = next(iter(mbti_dataset_line))[0].numpy()\n",
        "print(example_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "wXtIm_OBMMia",
        "outputId": "d25e8848-6b3d-429d-a8e3-fbb6c83bdb10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1720, 5494, 11623, 15192, 5633, 29152, 46299, 37417, 1720, 35224, 15957, 78792, 28173, 1099, 20789, 48355, 33563, 904, 35304, 23706, 46299, 46299, 46299]\n"
          ]
        }
      ],
      "source": [
        "encoded_example = encoder.encode(example_text)\n",
        "print(encoded_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9vTBESiMSl0"
      },
      "outputs": [],
      "source": [
        "def encode(text_tensor, label):\n",
        "  encoded_text = encoder.encode(text_tensor.numpy())\n",
        "  return encoded_text, label\n",
        "\n",
        "def encode_map_fn(text, label):\n",
        "  return tf.py_function(encode, inp=[text, label], Tout=(tf.int64, tf.int64))\n",
        "\n",
        "all_encoded_data = mbti_dataset_line.map(encode_map_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhnjY5UuMmn6"
      },
      "source": [
        "Split the dataset into test and train batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5Kb_Xr_MqkD"
      },
      "outputs": [],
      "source": [
        "train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\n",
        "train_data = train_data.padded_batch(BATCH_SIZE, padded_shapes=([-1],[]))\n",
        "\n",
        "test_data = all_encoded_data.take(TAKE_SIZE)\n",
        "test_data = test_data.padded_batch(BATCH_SIZE, padded_shapes=([-1],[]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "VpZ220tYMW_8",
        "outputId": "e5ca99f6-4168-4ff2-ee62-b76478c2b082"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(30,), dtype=int64, numpy=\n",
              " array([ 1720,  5494, 11623, 15192,  5633, 29152, 46299, 37417,  1720,\n",
              "        35224, 15957, 78792, 28173,  1099, 20789, 48355, 33563,   904,\n",
              "        35304, 23706, 46299, 46299, 46299,     0,     0,     0,     0,\n",
              "            0,     0,     0])>, <tf.Tensor: shape=(), dtype=int64, numpy=9>)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_text, sample_labels = next(iter(test_data))\n",
        "\n",
        "sample_text[0], sample_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9wgtWwDQTx3"
      },
      "outputs": [],
      "source": [
        "vocab_size += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQRm7E5zQbHa"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG9s7Zy_Ql_r"
      },
      "outputs": [],
      "source": [
        "model.add(tf.keras.layers.Embedding(vocab_size+1, 64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__BU9SgdQ0iO"
      },
      "outputs": [],
      "source": [
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjCj-HyKQ9m4"
      },
      "outputs": [],
      "source": [
        "for units in [64, 64]:\n",
        "  model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(16, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_efDhoZvQyVw"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "iw9VlQalRIcn",
        "outputId": "7f8f1869-b406-4738-a2e6-9aab6b1de33c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4203/4203 [==============================] - 482s 115ms/step - loss: 2.2360 - accuracy: 0.2242 - val_loss: 2.2317 - val_accuracy: 0.2238\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f46183f9d68>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_data, epochs=1, validation_data=test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "b7FQCc38eOKw",
        "outputId": "f17bfbe0-967e-4409-e26b-83f38be52606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     79/Unknown - 13s 168ms/step - loss: 2.2317 - accuracy: 0.2238\n",
            "Eval loss: 2.232, Eval accuracy: 0.224\n"
          ]
        }
      ],
      "source": [
        "eval_loss, eval_acc = model.evaluate(test_data)\n",
        "\n",
        "print('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results are still poor, and these two explorations prove that LSTM is indeed not suitable for this dataset and this problem."
      ],
      "metadata": {
        "id": "zWYEKRndEbiH"
      }
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}